import requests
from bs4 import BeautifulSoup
import time
import pprint

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
KEYWORDS = ['–¥–∏–∑–∞–π–Ω', '—Ñ–æ—Ç–æ', 'web', 'python']

# –ë–∞–∑–æ–≤—ã–π URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
BASE_URL = 'https://habr.com'

# –°–ø–∏—Å–æ–∫ URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
URLS = [
    f'{BASE_URL}/ru/articles/',
]

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'
                  ' Chrome/85.0.4183.121 Safari/537.36',
    'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'
}

def fetch_page(url):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º URL.
    """
    try:
        response = requests.get(url=url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        return response.text
    
    # –ù–µ–±–æ–ª—å—à–∞—è –æ—Ç–ª–∞–¥–∫–∞
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∫ —Å–∞–π—Ç—É –∏ —Ç.–¥.
    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {http_err}")
    except requests.exceptions.ConnectionError as conn_err:
        print(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {conn_err}")
    except requests.exceptions.Timeout as timeout_err:
        print(f"–¢–∞–π–º-–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {timeout_err}")
    except Exception as err:
        print(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {err}")
    return None

def parse_articles(html):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
    """
    soup = BeautifulSoup(html, 'html.parser')
    articles = soup.find_all('article')
    return articles

def extract_article_info(article):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å–µ: –∑–∞–≥–æ–ª–æ–≤–æ–∫, –¥–∞—Ç—É –∏ —Å—Å—ã–ª–∫—É.
    """
    title_tag = article.find('a', class_='tm-title__link', attrs={'data-article-link': 'true'})
    date_tag = article.find('time')
    
    if title_tag and date_tag:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–∞ 'title'
        date_text = date_tag.get('title', '').strip()
        if not date_text:
            date_text = date_tag.get_text(strip=True)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        original_title = title_tag.get_text(strip=True)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç–∞—Ç—å—é
        href = title_tag.get('href', '')
        if href.startswith('/'):
            link = BASE_URL + href
        else:
            link = href

        return {
            'title': original_title,
            'title_lower': original_title.lower(),
            'date': date_text,
            'link': link
        }
    return None

def fetch_full_text(url):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –ø–æ –µ—ë URL.
    """
    html = fetch_page(url)
    if html:
        soup = BeautifulSoup(html, 'html.parser')
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏
        possible_containers = [
            'div.post__text',          # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
            'div.article-formatted-body',  # –í–æ–∑–º–æ–∂–Ω–æ –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–π
            'div.tm-article-presenter__body', # –ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
            'div.article__text'        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
        ]
        
        content = None
        for selector in possible_containers:
            content = soup.select_one(selector)
            if content:
                break
        
        if content:
            # –£–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–≥–∏ –∏ –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç
            return content.get_text(separator='\n', strip=True)
        else:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –¥–ª—è {url}")
    else:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É {url}")
    return ""

def print_articles(articles_dict):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—á–∞—Ç–∏ —Å–ø–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π —Å –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏.
    """
    print("\n–°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π:")
    print("--------------")
    for number, article in articles_dict.items():
        category = "üìå –ö–ª—é—á–µ–≤–æ–µ" if article['category'] == 'matching' else "üìÑ –î—Ä—É–≥–æ–µ"
        print(f"{number}. [{category}] {article['date']} - {article['title']}")

def main():
    # –ü–æ–ª—É—á–∞–µ–º HTML –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
    all_articles_html = []
    for url in URLS:
        page_content = fetch_page(url)
        if page_content:
            articles = parse_articles(page_content)
            all_articles_html.extend(articles)
            print(f"–ù–∞–π–¥–µ–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {url}")
        else:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç —Å {url}")

    if not all_articles_html:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ç—å–∏ –Ω–∞ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö.")
        return

    matching_articles = []  # –°—Ç–∞—Ç—å–∏ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ –∏–ª–∏ —Ç–µ–∫—Å—Ç–µ
    other_articles = []     # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—å–∏

    print("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—å–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")

    # –ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π, –±—É–¥–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å —Å—Å—ã–ª–∫–∏
    processed_links = set()

    for article in all_articles_html:
        info = extract_article_info(article)
        if info and info['link'] not in processed_links:
            processed_links.add(info['link'])
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
            in_title = any(keyword in info['title_lower'] for keyword in KEYWORDS)

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ
            in_text = False

            if not in_title:
                # –ï—Å–ª–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –Ω–µ—Ç –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç–∞—Ç—å–∏
                full_text = fetch_full_text(info['link'])
                if any(keyword in full_text.lower() for keyword in KEYWORDS):
                    in_text = True
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Å–µ—Ä–≤–µ—Ä
                time.sleep(1)

            if in_title or in_text:
                matching_articles.append(info)
            else:
                other_articles.append(info)

    # –°–æ–∑–¥–∞–µ–º –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å —Å—Ç–∞—Ç–µ–π —Å —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π
    all_articles = {}
    current_number = 1

    for article in matching_articles:
        all_articles[current_number] = {
            'title': article['title'],
            'date': article['date'],
            'link': article['link'],
            'category': 'matching'
        }
        current_number += 1

    for article in other_articles:
        all_articles[current_number] = {
            'title': article['title'],
            'date': article['date'],
            'link': article['link'],
            'category': 'other'
        }
        current_number += 1

    if all_articles:
        print_articles(all_articles)
    else:
        print("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return

    # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤—ã–±—Ä–∞—Ç—å —Å—Ç–∞—Ç—å—é –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
    while True:
        try:
            choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä —Å—Ç–∞—Ç—å–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞): ").strip()
            if choice.lower() == 'exit':
                print("–í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã.")
                break
            choice = int(choice)
            if choice in all_articles:
                selected_article = all_articles[choice]
                # P.S:
                # –¢–ï–ö–°–¢ –ú–û–ñ–ï–¢ –í–´–í–û–î–ò–¢–¨–°–Ø –° –û–®–ò–ë–ö–ê–ú–ò(–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–∏–º–≤–æ–ª–æ–≤, –æ–±—Ä—ã–≤—ã –≤ —Ç–µ–∫—Å—Ç–µ –∏ —Ç.–¥)
                print(f"\n–ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—å—é: {selected_article['title']}\n{'=' * (len(selected_article['title']) + 17)}")
                full_text = fetch_full_text(selected_article['link'])
                if full_text:
                    print(full_text)
                else:
                    print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏.")
            else:
                print(f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ {len(all_articles)}.")
        except ValueError:
            print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä –∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞.")

if __name__ == "__main__":
    main()
